{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abir866/AbirGist/blob/main/Text%20Analysis\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58aec795",
      "metadata": {
        "id": "58aec795"
      },
      "source": [
        "<h1 align = \"center\">Computer Prog. & Problem Solving</h1>\n",
        "<h2 align = \"center\">CSCI 1227 - Spring, 2022</h2>\n",
        "\n",
        "<h3 align = \"center\"><u>Project 1</u>: File IO and Text Processing</h3>\n",
        "<h3 align = \"center\"><u> Prepared by</u>: M. Shamsuzzaman, PhD</h3>\n",
        "\n",
        "<h5 align = \"center\"><u> Document version#</u>: draft 1</h5>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "935fd065",
      "metadata": {
        "id": "935fd065"
      },
      "source": [
        "## Objective and Goals\n",
        "\n",
        "- How to work with a text file in Python (open, read/write, cleaning, etc.)\n",
        "- Bonus (optional): computation of entropy of letters  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ebbe61b",
      "metadata": {
        "id": "7ebbe61b"
      },
      "source": [
        "## Project Description\n",
        "\n",
        "In many cases, we need to read from a file and/or write to a file as part of our task. In this project, you are going to use the book **Through the Looking-Glass** by _Lewis Carroll_. The text version of the book `Through the Looking Glass.txt` is provided on **BrightSpace**. However, you can get the book from [here](https://www.gutenberg.org/ebooks/12) as part of the [Project Gutenberg](https://www.gutenberg.org/).\n",
        "\n",
        "The character set encoding of the text is `UTF-8`.  \n",
        "\n",
        "Your task is to write a program that can:\n",
        "1. Read the file and clean the text (remove all punctuations, non-ascii characters, all lower-case etc.)\n",
        "2. Split the text into words\n",
        "3. Count the total number of unique words in the book\n",
        "4. Find the longest word in the document, and its length\n",
        "5. Calculate the frequencies of \"word lengths\"\n",
        "6. Top 10 most used words and their frequencies\n",
        "7. Calculate the frequencies of letters\n",
        "8. Calculate the entropy of each letter (optional/bonus)\n",
        "9. Write your findings (3 to 8) to a text file (`summary.txt`).\n",
        "\n",
        "Note that,\n",
        "- _The frequencies of \"word lengths\"_ in 5 mean the total counts of 1-letter words, 2-letter words, 3-letter words,... etc.  \n",
        "- Similarly, in 6, word frequency mean the total count of a particular word. For example, the frequency of the word 'the' is the total number of times the word 'the' appears in the document.\n",
        "- In 7, you need to calculate the the total counts of individual letters (a-z) in the document.\n",
        "\n",
        "### Entropy\n",
        "\n",
        "[Entropy](https://en.wikipedia.org/wiki/Entropy_(information_theory)) is the measure of information content. If we want to calculate the entropy in unit of `bits`, we use the following equation:\n",
        "\n",
        "$$H = - \\sum_{i=1}^{n} p(x_i) \\log_2{(p(x_i))}$$\n",
        "\n",
        "Where,\n",
        "\n",
        "- $x$ are data values, and\n",
        "- $p$ is the probability\n",
        "\n",
        "In our case, $n$ is 26 (as there are 26 letters in English alphabet), and probability of a letter in the document can be calculated using the frequency of that letter divided by the sum of the frequency of all the letters.\n",
        "\n",
        "><u>Note</u>: This project is basically an extension of the Lab 6 and 7 combined."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile P1_Tufan.py\n",
        "# Worked from goggle colab\n",
        "import string\n",
        "from collections import OrderedDict\n",
        "from math import log\n",
        "def read_file(name : str)-> str:\n",
        "  \"\"\"A function to read a file whose path is the parameter name and return the cleaned text\n",
        "  \"\"\"\n",
        "  with open(name,\"r\") as input_file:\n",
        "    lines = input_file.read()\n",
        "  text = ...\n",
        "  st_no_digit = ''''''.join([n for n in lines if not n.isdigit()])\n",
        "  st_no_digit_punct = ''''''.join([alphabet for alphabet in st_no_digit if alphabet not in string.punctuation])\n",
        "  encoded_st = st_no_digit_punct.encode(\"ascii\", \"ignore\")\n",
        "  decode_st = encoded_st.decode()\n",
        "  text = ''''''.join([i.lower() for i in decode_st])\n",
        "  return text\n",
        "def unique_words(text : str, x = {} )->tuple:\n",
        "  \"\"\"A function to find the uniques words and their count from  the given text parameter\n",
        "  and return them together in as a tuple\n",
        "  \"\"\"\n",
        "  for i in text.split():\n",
        "   x[i] = x.get(i,0)+1\n",
        "  return len(x.keys()),x\n",
        "\n",
        "def find_longest_word(x : dict)->str:\n",
        "   \"\"\"A function to find the longest word from the dictionary as the given perameter\n",
        "   and return it with it's length a in a tuple\n",
        "   \"\"\"\n",
        "   length = max([len(i) for i in x.keys()])\n",
        "   tpl =()\n",
        "\n",
        "   for i in x.keys():\n",
        "    if length == len(i):\n",
        "      tpl+= (i,length)\n",
        "   return tpl\n",
        "def find_word_length_frequencies(y : str,x ={})->dict:\n",
        "  \"\"\"A fucntion to find the number of words from the given string parameter y\n",
        "  that are of same size  and return them in the given dictionary\n",
        "  \"\"\"\n",
        "  gather = [len(i) for i in y.split()]\n",
        "  for i in sorted(gather):\n",
        "    x[i]=x.get(i,0)+1\n",
        "  return x\n",
        "\n",
        "def find_ten_frequent_words(x : dict)->None:\n",
        "  \"\"\"A fucntion to find the top ten most frequen words from the given dictionary as parameter.\n",
        "  Return the top ten words as a dictionary\n",
        "  \"\"\"\n",
        "  ten_words ={}\n",
        "\n",
        "  values = x.values()\n",
        "  values =sorted(values)\n",
        "  values = values[-1:-11:-1]\n",
        "\n",
        "  while len(values) != 0:\n",
        "    for i in x:\n",
        "      if x[i] == max(values):\n",
        "        ten_words[i] = x.get(i,0)\n",
        "    values.remove(max(values))\n",
        "  return ten_words\n",
        "\n",
        "def find_letter_frequency(text : str, x : dict)->str:\n",
        "  \"\"\"A find the number of occurences of a particular alphabet from the given string y as parameter\n",
        "  and return them in the given dictionary x\n",
        "  \"\"\"\n",
        "  alphabets = string.ascii_lowercase\n",
        "  #print(alphabets)\n",
        "  for i in alphabets:\n",
        "    x[i] = text.count(i)\n",
        "  return x\n",
        "\n",
        "def calculate_entropy(x : dict)->dict:\n",
        "  \"\"\"A function to calculate the entropy of each letter from their frequency in the given x dictionary as a parameter\n",
        "  and return them as a dictionary\n",
        "  \"\"\"\n",
        "  y ={}\n",
        "  h = sum(x.values())\n",
        "  for i in x:\n",
        "   z = x.get(i)/h\n",
        "   y[i] = -z*log(z,2)\n",
        "  return y\n",
        "\n",
        "# Ready to write by opening a file (Working from google colab)\n",
        "out_file = open(\"summary.txt\",\"w\")\n",
        "\n",
        "# Call the read_file function with the path name to file to be read, present in temporary Goggle colab working directory\n",
        "text = read_file(\"/content/Through the Looking Glass.txt\")\n",
        "\n",
        "# Write the cleaned text in the file\n",
        "#out_file.write(text)\n",
        "\n",
        "dic ={} # Create an empty dictionary too sent to collect unique words\n",
        "\n",
        "# call the unique words method\n",
        "ln,dic = unique_words(text, dic)\n",
        "\n",
        "# Print the unique words in the file\n",
        "print(\"-\"*50+\"\\nUniqueWords\\n\"+\"-\"*50+\"\\n\", file = out_file)\n",
        "print(f\"{ln}\",file = out_file)\n",
        "# print('wwwgutenbergorg' in dic)\n",
        "\n",
        "# Call to the function find_longest_word to get the word\n",
        "long_word = find_longest_word(dic)\n",
        "\n",
        "#Print the longest words in file\n",
        "print(\"-\"*50+\"\\nLongest word\\n\"+\"-\"*50+\"\\n\", file = out_file)\n",
        "for i in range(len(long_word)):\n",
        "  if (i%2) == 0:\n",
        "   print(f\"{long_word[i]}\".ljust(30),file =out_file,end=\"\")\n",
        "  else:\n",
        "   print(f\"Length : {long_word[i]}\".rjust(10),file = out_file)\n",
        "# Remove the previous dictionary\n",
        "del(dic)\n",
        "\n",
        "# Call to find_word_length_frequencies and store the result in a new dictionary\n",
        "dic = find_word_length_frequencies(text)\n",
        "\n",
        "#Print the word length frequencies in the file\n",
        "print(\"-\"*50+\"\\nWordlength frequencies\\n\"+\"-\"*50+\"\\n\", file = out_file)\n",
        "print(f\"Word\".ljust(30)+f\"Frequency\".rjust(10),file = out_file)\n",
        "for itm in dic:\n",
        " print(f\"{itm}\".ljust(30)+f\"{dic.get(itm)}\".rjust(10),file = out_file)\n",
        "\n",
        "#Refer to a new dictionary\n",
        "dic ={}\n",
        "\n",
        "# Call to the unique words method again to get the unque words and their count in a tuple\n",
        "ln,dic = unique_words(text,dic)\n",
        "#print(dic)\n",
        "\n",
        "# Call to the find_ten_frequent_words  and passing the dictionary built\n",
        "dic = find_ten_frequent_words(dic)\n",
        "\n",
        "#Print the ten most frequent words with their frequencies in the file\n",
        "print(\"-\"*50+\"\\nTen Most Frequent Words\\n\"+\"-\"*50+\"\\n\", file = out_file)\n",
        "print(f\"Word\".ljust(30)+f\"Frequency\".rjust(10),file = out_file)\n",
        "for i in dic:\n",
        " print(f\"{i}\".ljust(30)+f\"{dic.get(i)}\".rjust(10),file = out_file)\n",
        "\n",
        "# Refer to a new dictionary again\n",
        "dic = {}\n",
        "\n",
        "# Call to the find_letter_fequency fucntion and store the result in that dictionary\n",
        "dic = find_letter_frequency(text,dic)\n",
        "\n",
        "#Print the letters with their frequency in the file\n",
        "print(\"-\"*50+\"\\nLetter Frequency\\n\"+\"-\"*50+\"\\n\", file = out_file)\n",
        "print(f\"Letter\".ljust(30)+f\"Frequency\".rjust(10),file = out_file)\n",
        "for it in dic:\n",
        " print(f\"{it}\".ljust(30)+f\"{dic.get(it)}\".rjust(10),file = out_file)\n",
        "\n",
        "# Call to the calculate_entropy function , passed with the already populated dictionary\n",
        "dic = calculate_entropy(dic)\n",
        "\n",
        "#Print the letter with their entropies in the file\n",
        "print(\"-\"*50+\"\\nLetter Entropy\\n\"+\"-\"*50+\"\\n\", file = out_file)\n",
        "print(f\"Letter\".ljust(30)+f\"Entropy\".rjust(10),file = out_file)\n",
        "for value in dic:\n",
        " print(f\"{value}\".ljust(30)+f\"{dic.get(value)}\".rjust(10),file = out_file)\n",
        "out_file.close()\n",
        "print(\"Done\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebbwlIOSgYfQ",
        "outputId": "71188cb4-ae1c-4671-ef09-40344bef16ad"
      },
      "id": "ebbwlIOSgYfQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing P1_Tufan.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  for i in x:\n",
        "    if x[i] in values:\n",
        "      print()\n",
        "      ten_words[i] = x.get(i,0)\n",
        "      values.insert(0,0)\n",
        "      print(len(values))"
      ],
      "metadata": {
        "id": "17cmUviF-ojM"
      },
      "id": "17cmUviF-ojM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "f5c9bb62",
      "metadata": {
        "id": "f5c9bb62"
      },
      "source": [
        "### Your Tasks:\n",
        "\n",
        "Complete all the tasks described in the project description and submit your completed script file in the designated folder @BrightSpace.\n",
        "\n",
        "\n",
        "Hints:\n",
        "- Use a function to complete each task\n",
        "\n",
        "Feel free to ask if you have any questions.\n",
        "\n",
        ">**Notify immediately, if you find any ambiguity and/or error in this document.**\n",
        "\n",
        "\n",
        "### Grading scheme :\n",
        "-    [1 pt] The program reads the file and cleans the text (removes all punctuations, non-ascii characters, all lower-case etc.)\n",
        "-    [1.5 pts] The program reports the total number of unique words in the book correctly\n",
        "-    [1.5 pts] The program reports the longest word in the document and its length correctly\n",
        "-    [1.5 pts] The program calculates and the frequencies of \"word lengths\" correctly\n",
        "-    [1.5 pts] The program reports top 10 most used words and their frequencies correctly\n",
        "-    [1 pt] The program reports the frequencies of letters correctly\n",
        "-    [1 pt] Correct use of functions, variable names, docstrings\n",
        "-    [1 pt] Summary.txt file contains the correct findings\n",
        "-    [1.5 pts: BONUS] The program calculates and reports the entropy of each letter correctly\n",
        "\n",
        "#### Submission deadline\n",
        "\n",
        "- The submission deadline for this project is **June 20, 2022**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fce1f7f4",
      "metadata": {
        "id": "fce1f7f4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
